{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making word2vec model\n",
    "In this ipython notebook we make the word2vec model and save it for future use.\n",
    "We also look further into the text and analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # dataframe\n",
    "import numpy as np # matrix maths\n",
    "from tqdm import tqdm # progress bar\n",
    "from helper import text_to_wordlist # NLP\n",
    "import gensim.models.word2vec as word2vec # word2vec model\n",
    "import multiprocessing # cpu_count\n",
    "import os # saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the questions\n",
    "train = pd.read_csv('~/Kaggle_Quora/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Total nan values: id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n",
      "[*]train.shape: (404288, 6)\n"
     ]
    }
   ],
   "source": [
    "# checking for total number of nan values\n",
    "print('[*]Total nan values:', train.isnull().sum())\n",
    "# so there are 2 nan values in question2, we will simply remove them\n",
    "# as we have sufficient data\n",
    "train = train.dropna()\n",
    "print('[*]train.shape:', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]Number of duplicate questions: 149263\n"
     ]
    }
   ],
   "source": [
    "q1 = train['question1'].values.tolist()\n",
    "q2 = train['question2'].values.tolist()\n",
    "dupli_true = sum(train['is_duplicate'])\n",
    "print('[*]Number of duplicate questions:', dupli_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the questions\n",
    "Now we tokenize the questions and see what are the total number of unique tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404288/404288 [00:51<00:00, 7891.23it/s]\n"
     ]
    }
   ],
   "source": [
    "q1_sent = []\n",
    "q2_sent = []\n",
    "for i in tqdm(range(len(q1))):\n",
    "    q1_sent.append(text_to_wordlist(q1[i]))\n",
    "    q2_sent.append(text_to_wordlist(q2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india']\n",
      "<class 'list'>\n",
      "what\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(q1_sent[0])\n",
    "print(type(q1_sent[0]))\n",
    "print(q1_sent[0][0])\n",
    "print(type(q1_sent[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_total = q1_sent\n",
    "q_total += q2_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'it', 'like', 'to', 'have', 'sex', 'with', 'your', 'cousin']\n",
      "808576\n"
     ]
    }
   ],
   "source": [
    "print(q_total[-1])\n",
    "print(len(q_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making our own Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word2vec parameters\n",
    "e_dim = 300 # embedding dimension\n",
    "min_word_count = 1 # minimum number of times a word comes so that it is registered\n",
    "num_workers = multiprocessing.cpu_count() # total number of workers\n",
    "context_size = 10 # number of words before and after the focus word\n",
    "# context_size is also the maximum distance between the current and predicted word within a sentence.\n",
    "downsampling = 1e-5 # threshold for configuring which higher-frequency words are randomly downsampled\n",
    "seed = 1 # seed value, helps with remaking the model\n",
    "sg = 0 # if sg = 0 CBOW is used, if sg = 1 skip-grams is used, default 0\n",
    "epochs = 5 # number of iters or epochs over the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the word2vec model --> CBOW\n",
    "w2vector_cbow = word2vec.Word2Vec(sg = sg, seed = seed, size = e_dim, workers = num_workers,\n",
    "                             min_count = min_word_count, window = context_size,\n",
    "                             sample = downsampling, iter = epochs)\n",
    "# building the vocabulary\n",
    "w2vector.build_vocab(q_total)\n",
    "print(\"Word2Vec vocabulary length:\", len(w2vector_cbow.wv.vocab))\n",
    "\n",
    "# training the model\n",
    "w2vector.train(q_total, total_examples = w2vector_cbow.corpus_count, epochs = w2vector_cbow.iter)\n",
    "\n",
    "# saving the model\n",
    "if not os._exists('trained'):\n",
    "    os.makedirs('trained')\n",
    "w2vector_cbow.save(os.path.join('trained', 'w2vector_CBOW.w2v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip Grams model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 86005\n"
     ]
    }
   ],
   "source": [
    "# Making the word2vec model --> skip_grams\n",
    "w2vector_sg = word2vec.Word2Vec(sg = 1, seed = seed, size = e_dim, workers = num_workers,\n",
    "                             min_count = min_word_count, window = context_size,\n",
    "                             sample = downsampling, iter = epochs)\n",
    "\n",
    "# building the vocabulary\n",
    "w2vector_sg.build_vocab(q_total)\n",
    "print(\"Word2Vec vocabulary length:\", len(w2vector_sg.wv.vocab))\n",
    "\n",
    "# training the model\n",
    "w2vector_sg.train(q_total, total_examples = w2vector_sg.corpus_count, epochs = w2vector_sg.iter)\n",
    "\n",
    "# saving the model\n",
    "if not os._exists('trained'):\n",
    "    os.makedirs('trained')\n",
    "w2vector_sg.save(os.path.join('trained', 'w2vector_sg.w2v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "Now that we have saved the model, we are going to play around with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countries', 0.893531322479248),\n",
       " ('nation', 0.855096697807312),\n",
       " ('asia', 0.8382056355476379),\n",
       " ('china', 0.837762713432312),\n",
       " ('indonesia', 0.8323123455047607),\n",
       " ('foreigner', 0.8274473547935486),\n",
       " ('european', 0.8260392546653748),\n",
       " ('superpower', 0.8230191469192505),\n",
       " ('africa', 0.8229018449783325),\n",
       " ('decades', 0.8225271105766296)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vector_sg.most_similar('country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = w2vector_sg.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat is related to eating, as drink is related to drinking\n",
      "drink is related to drinking, as license is related to driving\n",
      "man is related to king, as woman is related to queen\n",
      "quit is related to india, as quitting is related to india\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'quitting'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple tasks for word2vec model\n",
    "nearest_similarity_cosmul(\"eat\", \"eating\", \"drinking\")\n",
    "nearest_similarity_cosmul(\"drink\", \"drinking\", \"driving\")\n",
    "nearest_similarity_cosmul(\"man\", \"king\", \"queen\")\n",
    "nearest_similarity_cosmul(\"quit\", \"india\", \"india\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
